---
title: "Modeling Performance and Power on Disparate Platforms using Transfer Learning with Machine Learning Models"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here 
# and it will be replaced with their full name and linked to their profile.
authors:
- Amit Mankodi
- Amit Bhatt
- Bhaskar Chaudhary
- Rajat Kumar
- Aditya Amrutiya


date: "2020-12-27T00:00:00Z"
doi: "https://doi.org/10.1109/BID.2017.8336587"

# Schedule page publish date (NOT publication's date).
# publishDate: "2021-02-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["3"]

# Publication name and optional abbreviated publication name.
publication: In *2020 International Conference on Modeling, Simulations and Optimizations (CoMSO2020)*
publication_short: In * To be Published in Springer*

abstract: Cross prediction is an active research area. Many research works have used cross prediction to predict the target system's performance and power from the machine learning model trained on the source system. The source and target systems differ either in terms of instruction-set or hardware features. A widely used transfer learning technique utilizes the knowledge from a trained machine learning from one problem to predict targets in similar problems. In this work, we use transfer learning to achieve cross-system and cross-platform predictions. In cross-system prediction, we predict the physical system's performance (runtime) and power from the simulation systems dataset while predicting performance and the power for target system from source system both having different instruction-set in cross-platform prediction. We achieve runtime prediction accuracy of 90% and 80% and power prediction accuracy of 75% and 80% in cross-system and cross-platform predictions, respectively, for the best performing deep neural network model. Furthermore , we have evaluated the accuracy of univariate and multivariate machine learning models, the accuracy of compute-intensive and data-intensive applications, and the accuracy of the simulation and physical systems.

# Summary. An optional shortened abstract.

summary: Cross prediction is an active research area. Many research works have used cross prediction to predict the target system's performance and power from the machine learning model trained on the source system. The source and target systems differ either in terms of instruction-set or hardware features. A widely used transfer learning technique utilizes the knowledge from a trained machine learning from one problem to predict targets in similar problems. In this work, we use transfer learning to achieve cross-system and cross-platform predictions. In cross-system prediction, we predict the physical system's performance (runtime) and power from the simulation systems dataset while predicting performance and the power for target system from source system both having different instruction-set in cross-platform prediction. We achieve runtime prediction accuracy of 90% and 80% and power prediction accuracy of 75% and 80% in cross-system and cross-platform predictions, respectively, for the best performing deep neural network model. Furthermore , we have evaluated the accuracy of univariate and multivariate machine learning models, the accuracy of compute-intensive and data-intensive applications, and the accuracy of the simulation and physical systems.
tags: [	
Multivariate Performance and Power Prediction,
Transfer Learning,
Machine Learning,
Cross Prediction]

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: ''
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- example

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---

{{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
